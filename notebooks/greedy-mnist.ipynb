{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Selección de clientes con Active Federated Learning - MNIST\n",
        "\n",
        "En este notebook vamos a utilizar nuestro modelo de entrenamiento en Aprendizaje Federado utilizando AFL como algoritmo de selección de clientes [1] sobre el dataset de MNIST, que es un conjunto de imágenes de dígitos manuscritos del 0 al 9 [2]. Se trata de un problema de visión por computador al que usaremos para comparar el rendimiento del método de selección AFL frente al convencional.\n",
        "\n",
        "> [1] https://arxiv.org/abs/1909.12641.\n",
        ">\n",
        "> [2] http://yann.lecun.com/exdb/mnist."
      ],
      "metadata": {
        "id": "QzFVvanFrrwe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4BfI6bDrg3o",
        "outputId": "0f6eeef3-59ba-4c9b-9e1c-7733a1a152e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FLEXible is not installed.\n",
            "Installing dependency flexible-fl...\n",
            "Collecting flexible-fl\n",
            "  Downloading flexible_fl-0.6.1-py3-none-any.whl (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.8/85.8 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from flexible-fl) (1.25.2)\n",
            "Collecting multiprocess (from flexible-fl)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from flexible-fl) (1.2.2)\n",
            "Collecting cardinality (from flexible-fl)\n",
            "  Downloading cardinality-0.1.1.tar.gz (2.3 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sultan (from flexible-fl)\n",
            "  Downloading sultan-0.9.1-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from flexible-fl) (4.66.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from flexible-fl) (1.11.4)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (from flexible-fl) (5.1.0)\n",
            "Collecting tensorly (from flexible-fl)\n",
            "  Downloading tensorly-0.8.1-py3-none-any.whl (229 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.7/229.7 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown->flexible-fl) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown->flexible-fl) (3.15.3)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown->flexible-fl) (2.31.0)\n",
            "Collecting dill>=0.3.8 (from multiprocess->flexible-fl)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->flexible-fl) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->flexible-fl) (3.5.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown->flexible-fl) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown->flexible-fl) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown->flexible-fl) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown->flexible-fl) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown->flexible-fl) (2024.6.2)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown->flexible-fl) (1.7.1)\n",
            "Building wheels for collected packages: cardinality\n",
            "  Building wheel for cardinality (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cardinality: filename=cardinality-0.1.1-py3-none-any.whl size=2587 sha256=d97208023c7a8dba4a122fc17ae779f38b7a52859e00af522e6e4f7981cb9116\n",
            "  Stored in directory: /root/.cache/pip/wheels/b8/19/d1/2665c004b583a7d1880fa59055a3e462d6e35841a01b57010b\n",
            "Successfully built cardinality\n",
            "Installing collected packages: sultan, cardinality, dill, tensorly, multiprocess, flexible-fl\n",
            "Successfully installed cardinality-0.1.1 dill-0.3.8 flexible-fl-0.6.1 multiprocess-0.70.16 sultan-0.9.1 tensorly-0.8.1\n"
          ]
        }
      ],
      "source": [
        "# install FLEXible framework if not installed\n",
        "try:\n",
        "    import flex\n",
        "    print(\"FLEXible is installed.\")\n",
        "except:\n",
        "    print(\"FLEXible is not installed.\\nInstalling dependency flexible-fl...\")\n",
        "    !pip install flexible-fl"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_loss_accuracy(loss, accuracy):\n",
        "    # Example data\n",
        "    epochs = range(1, len(loss) + 1)\n",
        "\n",
        "    # Plot loss\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, loss, 'b', label='Loss')\n",
        "    plt.title('Loss over Epochs')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot accuracy\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs, accuracy, 'g', label='Accuracy')\n",
        "    plt.title('Accuracy over Epochs')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    # Show the plots\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "-31n0URu8tVs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# select device\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
        ")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "5jdIu00Ftc1u",
        "outputId": "5df8da6e-5d43-4b26-c3be-9315346e282d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from flex.datasets import load\n",
        "from torchvision import transforms\n",
        "\n",
        "flex_dataset, test_data = load(\"federated_emnist\", return_test=True, split=\"digits\")\n",
        "\n",
        "# Assign test data to server_id\n",
        "server_id = \"server\"\n",
        "flex_dataset[server_id] = test_data\n",
        "\n",
        "mnist_transforms = transforms.Compose(\n",
        "    [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "CYOy-Bmsu0_J",
        "outputId": "55650f6f-087d-4218-bb37-a4661241c76c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1fl9fRPPxTUxnC56ACzZ8JiLiew0SMFwt\n",
            "From (redirected): https://drive.google.com/uc?id=1fl9fRPPxTUxnC56ACzZ8JiLiew0SMFwt&confirm=t&uuid=b7ecfe48-54cc-45ee-a2f5-f3e96734fe67\n",
            "To: /content/emnist-digits.mat\n",
            "100%|██████████| 90.7M/90.7M [00:04<00:00, 19.7MB/s]\n",
            "\u001b[36m[sultan]: md5 -q ./emnist-digits.mat;\u001b[0m\n",
            "DEBUG:sultan:md5 -q ./emnist-digits.mat;\n",
            "\u001b[01;31m[sultan]: Unable to run 'md5 -q ./emnist-digits.mat;'\u001b[0m\n",
            "CRITICAL:sultan:Unable to run 'md5 -q ./emnist-digits.mat;'\n",
            "\u001b[01;31m[sultan]: --{ TRACEBACK }----------------------------------------------------------------------------------------------------\u001b[0m\n",
            "CRITICAL:sultan:--{ TRACEBACK }----------------------------------------------------------------------------------------------------\n",
            "\u001b[01;31m[sultan]: | NoneType: None\u001b[0m\n",
            "CRITICAL:sultan:| NoneType: None\n",
            "\u001b[01;31m[sultan]: | \u001b[0m\n",
            "CRITICAL:sultan:| \n",
            "\u001b[01;31m[sultan]: -------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
            "CRITICAL:sultan:-------------------------------------------------------------------------------------------------------------------\n",
            "\u001b[01;31m[sultan]: --{ STDERR }-------------------------------------------------------------------------------------------------------\u001b[0m\n",
            "CRITICAL:sultan:--{ STDERR }-------------------------------------------------------------------------------------------------------\n",
            "\u001b[01;31m[sultan]: | /bin/sh: 1: md5: not found\u001b[0m\n",
            "CRITICAL:sultan:| /bin/sh: 1: md5: not found\n",
            "\u001b[01;31m[sultan]: -------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
            "CRITICAL:sultan:-------------------------------------------------------------------------------------------------------------------\n",
            "\u001b[33m[sultan]: The following are additional information that can be used to debug this exception.\u001b[0m\n",
            "WARNING:sultan:The following are additional information that can be used to debug this exception.\n",
            "\u001b[33m[sultan]: The following is the context used to run:\u001b[0m\n",
            "WARNING:sultan:The following is the context used to run:\n",
            "\u001b[33m[sultan]: \t - cwd: None\u001b[0m\n",
            "WARNING:sultan:\t - cwd: None\n",
            "\u001b[33m[sultan]: \t - sudo: False\u001b[0m\n",
            "WARNING:sultan:\t - sudo: False\n",
            "\u001b[33m[sultan]: \t - user: root\u001b[0m\n",
            "WARNING:sultan:\t - user: root\n",
            "\u001b[33m[sultan]: \t - hostname: None\u001b[0m\n",
            "WARNING:sultan:\t - hostname: None\n",
            "\u001b[33m[sultan]: \t - env: None\u001b[0m\n",
            "WARNING:sultan:\t - env: None\n",
            "\u001b[33m[sultan]: \t - logging: True\u001b[0m\n",
            "WARNING:sultan:\t - logging: True\n",
            "\u001b[33m[sultan]: \t - executable: None\u001b[0m\n",
            "WARNING:sultan:\t - executable: None\n",
            "\u001b[33m[sultan]: \t - ssh_config: \u001b[0m\n",
            "WARNING:sultan:\t - ssh_config: \n",
            "\u001b[33m[sultan]: \t - src: None\u001b[0m\n",
            "WARNING:sultan:\t - src: None\n",
            "\u001b[01;31m[sultan]: Unable to run 'md5 -q ./emnist-digits.mat;'\u001b[0m\n",
            "CRITICAL:sultan:Unable to run 'md5 -q ./emnist-digits.mat;'\n",
            "\u001b[01;31m[sultan]: --{ TRACEBACK }----------------------------------------------------------------------------------------------------\u001b[0m\n",
            "CRITICAL:sultan:--{ TRACEBACK }----------------------------------------------------------------------------------------------------\n",
            "\u001b[01;31m[sultan]: | Traceback (most recent call last):\u001b[0m\n",
            "CRITICAL:sultan:| Traceback (most recent call last):\n",
            "\u001b[01;31m[sultan]: |   File \"/usr/local/lib/python3.10/dist-packages/sultan/api.py\", line 212, in run\u001b[0m\n",
            "CRITICAL:sultan:|   File \"/usr/local/lib/python3.10/dist-packages/sultan/api.py\", line 212, in run\n",
            "\u001b[01;31m[sultan]: |     result = Result(process, commands, self._context, streaming, halt_on_nonzero=halt_on_nonzero)\u001b[0m\n",
            "CRITICAL:sultan:|     result = Result(process, commands, self._context, streaming, halt_on_nonzero=halt_on_nonzero)\n",
            "\u001b[01;31m[sultan]: |   File \"/usr/local/lib/python3.10/dist-packages/sultan/result.py\", line 59, in __init__\u001b[0m\n",
            "CRITICAL:sultan:|   File \"/usr/local/lib/python3.10/dist-packages/sultan/result.py\", line 59, in __init__\n",
            "\u001b[01;31m[sultan]: |     self.dump_exception()\u001b[0m\n",
            "CRITICAL:sultan:|     self.dump_exception()\n",
            "\u001b[01;31m[sultan]: |   File \"/usr/local/lib/python3.10/dist-packages/sultan/result.py\", line 114, in dump_exception\u001b[0m\n",
            "CRITICAL:sultan:|   File \"/usr/local/lib/python3.10/dist-packages/sultan/result.py\", line 114, in dump_exception\n",
            "\u001b[01;31m[sultan]: |     raise self._exception\u001b[0m\n",
            "CRITICAL:sultan:|     raise self._exception\n",
            "\u001b[01;31m[sultan]: |   File \"/usr/local/lib/python3.10/dist-packages/sultan/result.py\", line 95, in dump_exception\u001b[0m\n",
            "CRITICAL:sultan:|   File \"/usr/local/lib/python3.10/dist-packages/sultan/result.py\", line 95, in dump_exception\n",
            "\u001b[01;31m[sultan]: |     raise subprocess.CalledProcessError(self.rc, ''.join(self._commands), self.stderr)\u001b[0m\n",
            "CRITICAL:sultan:|     raise subprocess.CalledProcessError(self.rc, ''.join(self._commands), self.stderr)\n",
            "\u001b[01;31m[sultan]: | subprocess.CalledProcessError: Command 'md5 -q ./emnist-digits.mat;' returned non-zero exit status 127.\u001b[0m\n",
            "CRITICAL:sultan:| subprocess.CalledProcessError: Command 'md5 -q ./emnist-digits.mat;' returned non-zero exit status 127.\n",
            "\u001b[01;31m[sultan]: | \u001b[0m\n",
            "CRITICAL:sultan:| \n",
            "\u001b[01;31m[sultan]: -------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
            "CRITICAL:sultan:-------------------------------------------------------------------------------------------------------------------\n",
            "\u001b[33m[sultan]: The following are additional information that can be used to debug this exception.\u001b[0m\n",
            "WARNING:sultan:The following are additional information that can be used to debug this exception.\n",
            "\u001b[33m[sultan]: The following is the context used to run:\u001b[0m\n",
            "WARNING:sultan:The following is the context used to run:\n",
            "\u001b[33m[sultan]: \t - cwd: None\u001b[0m\n",
            "WARNING:sultan:\t - cwd: None\n",
            "\u001b[33m[sultan]: \t - sudo: False\u001b[0m\n",
            "WARNING:sultan:\t - sudo: False\n",
            "\u001b[33m[sultan]: \t - user: root\u001b[0m\n",
            "WARNING:sultan:\t - user: root\n",
            "\u001b[33m[sultan]: \t - hostname: None\u001b[0m\n",
            "WARNING:sultan:\t - hostname: None\n",
            "\u001b[33m[sultan]: \t - env: None\u001b[0m\n",
            "WARNING:sultan:\t - env: None\n",
            "\u001b[33m[sultan]: \t - logging: True\u001b[0m\n",
            "WARNING:sultan:\t - logging: True\n",
            "\u001b[33m[sultan]: \t - executable: None\u001b[0m\n",
            "WARNING:sultan:\t - executable: None\n",
            "\u001b[33m[sultan]: \t - ssh_config: \u001b[0m\n",
            "WARNING:sultan:\t - ssh_config: \n",
            "\u001b[33m[sultan]: \t - src: None\u001b[0m\n",
            "WARNING:sultan:\t - src: None\n",
            "\u001b[36m[sultan]: md5sum ./emnist-digits.mat | cut -f 1 -d \" \";\u001b[0m\n",
            "DEBUG:sultan:md5sum ./emnist-digits.mat | cut -f 1 -d \" \";\n",
            "\u001b[36m[sultan]: md5 -q ./emnist-digits.mat;\u001b[0m\n",
            "DEBUG:sultan:md5 -q ./emnist-digits.mat;\n",
            "\u001b[01;31m[sultan]: Unable to run 'md5 -q ./emnist-digits.mat;'\u001b[0m\n",
            "CRITICAL:sultan:Unable to run 'md5 -q ./emnist-digits.mat;'\n",
            "\u001b[01;31m[sultan]: --{ TRACEBACK }----------------------------------------------------------------------------------------------------\u001b[0m\n",
            "CRITICAL:sultan:--{ TRACEBACK }----------------------------------------------------------------------------------------------------\n",
            "\u001b[01;31m[sultan]: | NoneType: None\u001b[0m\n",
            "CRITICAL:sultan:| NoneType: None\n",
            "\u001b[01;31m[sultan]: | \u001b[0m\n",
            "CRITICAL:sultan:| \n",
            "\u001b[01;31m[sultan]: -------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
            "CRITICAL:sultan:-------------------------------------------------------------------------------------------------------------------\n",
            "\u001b[01;31m[sultan]: --{ STDERR }-------------------------------------------------------------------------------------------------------\u001b[0m\n",
            "CRITICAL:sultan:--{ STDERR }-------------------------------------------------------------------------------------------------------\n",
            "\u001b[01;31m[sultan]: | /bin/sh: 1: md5: not found\u001b[0m\n",
            "CRITICAL:sultan:| /bin/sh: 1: md5: not found\n",
            "\u001b[01;31m[sultan]: -------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
            "CRITICAL:sultan:-------------------------------------------------------------------------------------------------------------------\n",
            "\u001b[33m[sultan]: The following are additional information that can be used to debug this exception.\u001b[0m\n",
            "WARNING:sultan:The following are additional information that can be used to debug this exception.\n",
            "\u001b[33m[sultan]: The following is the context used to run:\u001b[0m\n",
            "WARNING:sultan:The following is the context used to run:\n",
            "\u001b[33m[sultan]: \t - cwd: None\u001b[0m\n",
            "WARNING:sultan:\t - cwd: None\n",
            "\u001b[33m[sultan]: \t - sudo: False\u001b[0m\n",
            "WARNING:sultan:\t - sudo: False\n",
            "\u001b[33m[sultan]: \t - user: root\u001b[0m\n",
            "WARNING:sultan:\t - user: root\n",
            "\u001b[33m[sultan]: \t - hostname: None\u001b[0m\n",
            "WARNING:sultan:\t - hostname: None\n",
            "\u001b[33m[sultan]: \t - env: None\u001b[0m\n",
            "WARNING:sultan:\t - env: None\n",
            "\u001b[33m[sultan]: \t - logging: True\u001b[0m\n",
            "WARNING:sultan:\t - logging: True\n",
            "\u001b[33m[sultan]: \t - executable: None\u001b[0m\n",
            "WARNING:sultan:\t - executable: None\n",
            "\u001b[33m[sultan]: \t - ssh_config: \u001b[0m\n",
            "WARNING:sultan:\t - ssh_config: \n",
            "\u001b[33m[sultan]: \t - src: None\u001b[0m\n",
            "WARNING:sultan:\t - src: None\n",
            "\u001b[01;31m[sultan]: Unable to run 'md5 -q ./emnist-digits.mat;'\u001b[0m\n",
            "CRITICAL:sultan:Unable to run 'md5 -q ./emnist-digits.mat;'\n",
            "\u001b[01;31m[sultan]: --{ TRACEBACK }----------------------------------------------------------------------------------------------------\u001b[0m\n",
            "CRITICAL:sultan:--{ TRACEBACK }----------------------------------------------------------------------------------------------------\n",
            "\u001b[01;31m[sultan]: | Traceback (most recent call last):\u001b[0m\n",
            "CRITICAL:sultan:| Traceback (most recent call last):\n",
            "\u001b[01;31m[sultan]: |   File \"/usr/local/lib/python3.10/dist-packages/sultan/api.py\", line 212, in run\u001b[0m\n",
            "CRITICAL:sultan:|   File \"/usr/local/lib/python3.10/dist-packages/sultan/api.py\", line 212, in run\n",
            "\u001b[01;31m[sultan]: |     result = Result(process, commands, self._context, streaming, halt_on_nonzero=halt_on_nonzero)\u001b[0m\n",
            "CRITICAL:sultan:|     result = Result(process, commands, self._context, streaming, halt_on_nonzero=halt_on_nonzero)\n",
            "\u001b[01;31m[sultan]: |   File \"/usr/local/lib/python3.10/dist-packages/sultan/result.py\", line 59, in __init__\u001b[0m\n",
            "CRITICAL:sultan:|   File \"/usr/local/lib/python3.10/dist-packages/sultan/result.py\", line 59, in __init__\n",
            "\u001b[01;31m[sultan]: |     self.dump_exception()\u001b[0m\n",
            "CRITICAL:sultan:|     self.dump_exception()\n",
            "\u001b[01;31m[sultan]: |   File \"/usr/local/lib/python3.10/dist-packages/sultan/result.py\", line 114, in dump_exception\u001b[0m\n",
            "CRITICAL:sultan:|   File \"/usr/local/lib/python3.10/dist-packages/sultan/result.py\", line 114, in dump_exception\n",
            "\u001b[01;31m[sultan]: |     raise self._exception\u001b[0m\n",
            "CRITICAL:sultan:|     raise self._exception\n",
            "\u001b[01;31m[sultan]: |   File \"/usr/local/lib/python3.10/dist-packages/sultan/result.py\", line 95, in dump_exception\u001b[0m\n",
            "CRITICAL:sultan:|   File \"/usr/local/lib/python3.10/dist-packages/sultan/result.py\", line 95, in dump_exception\n",
            "\u001b[01;31m[sultan]: |     raise subprocess.CalledProcessError(self.rc, ''.join(self._commands), self.stderr)\u001b[0m\n",
            "CRITICAL:sultan:|     raise subprocess.CalledProcessError(self.rc, ''.join(self._commands), self.stderr)\n",
            "\u001b[01;31m[sultan]: | subprocess.CalledProcessError: Command 'md5 -q ./emnist-digits.mat;' returned non-zero exit status 127.\u001b[0m\n",
            "CRITICAL:sultan:| subprocess.CalledProcessError: Command 'md5 -q ./emnist-digits.mat;' returned non-zero exit status 127.\n",
            "\u001b[01;31m[sultan]: | \u001b[0m\n",
            "CRITICAL:sultan:| \n",
            "\u001b[01;31m[sultan]: -------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
            "CRITICAL:sultan:-------------------------------------------------------------------------------------------------------------------\n",
            "\u001b[33m[sultan]: The following are additional information that can be used to debug this exception.\u001b[0m\n",
            "WARNING:sultan:The following are additional information that can be used to debug this exception.\n",
            "\u001b[33m[sultan]: The following is the context used to run:\u001b[0m\n",
            "WARNING:sultan:The following is the context used to run:\n",
            "\u001b[33m[sultan]: \t - cwd: None\u001b[0m\n",
            "WARNING:sultan:\t - cwd: None\n",
            "\u001b[33m[sultan]: \t - sudo: False\u001b[0m\n",
            "WARNING:sultan:\t - sudo: False\n",
            "\u001b[33m[sultan]: \t - user: root\u001b[0m\n",
            "WARNING:sultan:\t - user: root\n",
            "\u001b[33m[sultan]: \t - hostname: None\u001b[0m\n",
            "WARNING:sultan:\t - hostname: None\n",
            "\u001b[33m[sultan]: \t - env: None\u001b[0m\n",
            "WARNING:sultan:\t - env: None\n",
            "\u001b[33m[sultan]: \t - logging: True\u001b[0m\n",
            "WARNING:sultan:\t - logging: True\n",
            "\u001b[33m[sultan]: \t - executable: None\u001b[0m\n",
            "WARNING:sultan:\t - executable: None\n",
            "\u001b[33m[sultan]: \t - ssh_config: \u001b[0m\n",
            "WARNING:sultan:\t - ssh_config: \n",
            "\u001b[33m[sultan]: \t - src: None\u001b[0m\n",
            "WARNING:sultan:\t - src: None\n",
            "\u001b[36m[sultan]: md5sum ./emnist-digits.mat | cut -f 1 -d \" \";\u001b[0m\n",
            "DEBUG:sultan:md5sum ./emnist-digits.mat | cut -f 1 -d \" \";\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usamos el decorador `@init_model_server` para inicializar el modelo en el servidor. Aprovechamos esta fase para simplemente definir nuestra arquitectura de red así como el optimizador y la función de pérdida."
      ],
      "metadata": {
        "id": "WB9yluACv2rm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from flex.pool import init_server_model\n",
        "from flex.pool import FlexPool\n",
        "from flex.model import FlexModel\n",
        "\n",
        "\n",
        "# Simple two Fully-Connected layer net\n",
        "class SimpleNet(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(28 * 28, 128)\n",
        "        self.fc2 = nn.Linear(128, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        # return logits\n",
        "        return x\n",
        "\n",
        "\n",
        "@init_server_model\n",
        "def build_server_model():\n",
        "    server_flex_model = FlexModel()\n",
        "\n",
        "    server_flex_model[\"model\"] = SimpleNet()\n",
        "    # Required to store this for later stages of the FL training process\n",
        "    server_flex_model[\"criterion\"] = torch.nn.CrossEntropyLoss()\n",
        "    server_flex_model[\"optimizer_func\"] = torch.optim.Adam\n",
        "    server_flex_model[\"optimizer_kwargs\"] = {}\n",
        "    return server_flex_model\n",
        "\n",
        "\n",
        "flex_pool = FlexPool.client_server_pool(\n",
        "    flex_dataset, server_id=server_id, init_func=build_server_model\n",
        ")\n",
        "\n",
        "clients = flex_pool.clients\n",
        "servers = flex_pool.servers\n",
        "aggregators = flex_pool.aggregators\n",
        "\n",
        "print(\n",
        "    f\"Number of nodes in the pool {len(flex_pool)}: {len(servers)} server plus {len(clients)} clients. The server is also an aggregator\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zAxWjwavQJ0",
        "outputId": "db39a5d5-bdff-4a9e-a91f-a9757be90a25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of nodes in the pool 3580: 1 server plus 3579 clients. The server is also an aggregator\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para comparar nuestro modelo con selección AFL, vamos a primero construir un método de selección de clientes aleatorio uniforme, por ejemplo, de $20$ clientes por ronda. Más adelante, implementaremos la selección con AFL con $m=20$ clientes por ronda."
      ],
      "metadata": {
        "id": "C3LoDmezyvud"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select clients\n",
        "clients_per_round = 20\n",
        "selected_clients_pool = clients.select(clients_per_round)\n",
        "selected_clients = selected_clients_pool.clients\n",
        "\n",
        "print(f'Server node is indentified by key \"{servers.actor_ids[0]}\"')\n",
        "print(\n",
        "    f\"Selected {len(selected_clients.actor_ids)} client nodes of a total of {len(clients.actor_ids)}\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFaDpYaWxbWm",
        "outputId": "2ccf35bb-101e-4b29-b6b1-1de467c1ab6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Server node is indentified by key \"server\"\n",
            "Selected 20 client nodes of a total of 3579\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utilizamos el decorador `@deploy_server_model` para distribuir el modelo del servidor a los clientes. Usamos `map` sobre los clientes seleccionados: `selected_clients`."
      ],
      "metadata": {
        "id": "R5LzYqxUzIaU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from flex.pool import deploy_server_model\n",
        "import copy\n",
        "\n",
        "\n",
        "@deploy_server_model\n",
        "def copy_server_model_to_clients(server_flex_model: FlexModel):\n",
        "    return copy.deepcopy(server_flex_model)\n",
        "\n",
        "\n",
        "servers.map(copy_server_model_to_clients, selected_clients)"
      ],
      "metadata": {
        "id": "UwxXBCoCytZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementamos la función de training para el que cada cliente avanza un número $n$ de pasos del optimizador (En este caso SGD-Adam [1]) sobre un _batch_ de $b$ imágenes. En nuestro caso, utilizaremos los mismo parámetros que en el ejemplo de FLEX [2]: $n=5, b=20$.\n",
        "\n",
        "> [1] https://arxiv.org/abs/1412.6980.\n",
        ">\n",
        "> [2] [Federated MNIST PT Example](https://github.com/FLEXible-FL/FLEXible/blob/main/notebooks/Federated%20MNIST%20PT%20example%20with%20flexible%20decorators.ipynb)"
      ],
      "metadata": {
        "id": "U1S01aEFzevA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from flex.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "def train(client_flex_model: FlexModel, client_data: Dataset):\n",
        "    train_dataset = client_data.to_torchvision_dataset(transform=mnist_transforms)\n",
        "    client_dataloader = DataLoader(train_dataset, batch_size=20)\n",
        "    model = client_flex_model[\"model\"]\n",
        "    optimizer = client_flex_model[\"optimizer_func\"](\n",
        "        model.parameters(), **client_flex_model[\"optimizer_kwargs\"]\n",
        "    )\n",
        "    model = model.train()\n",
        "    model = model.to(device)\n",
        "    criterion = client_flex_model[\"criterion\"]\n",
        "    for _ in range(5):\n",
        "        for imgs, labels in client_dataloader:\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            pred = model(imgs)\n",
        "            loss = criterion(pred, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "\n",
        "selected_clients.map(train)"
      ],
      "metadata": {
        "id": "UvjgKEJ7zdzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Con el decorador `@collect_clients_weights` recuperamos los pesos de PyTorch de cada cliente seleccionado para esa ronda. En el caso de PyTorch, el modelo devuelve los pesos en forma de un diccionario con `state_dict` para el que cada nombre representa una capa de la red y sus parámetros, lo que hacemos será devolver una lista con los valores de ese diccionario correspondientes a los pesos de la red entera."
      ],
      "metadata": {
        "id": "dMSabAvG0u2J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from flex.pool import collect_clients_weights\n",
        "\n",
        "\n",
        "@collect_clients_weights\n",
        "def get_clients_weights(client_flex_model: FlexModel):\n",
        "    weight_dict = client_flex_model[\"model\"].state_dict()\n",
        "    return [weight_dict[name] for name in weight_dict]\n",
        "\n",
        "\n",
        "aggregators.map(get_clients_weights, selected_clients)"
      ],
      "metadata": {
        "id": "ggbUniMr0oGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utilizamos el decorador `@aggregate_weights` para poder agregar los pesos que hemos recuperado de los clientes en la fase anterior computando la media de los pesos, conocido como agregador FedAvg, donde realizamos la media por columnas para cada capa de pesos."
      ],
      "metadata": {
        "id": "1DT76cJ41uFY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from flex.pool import aggregate_weights\n",
        "import tensorly as tl\n",
        "\n",
        "tl.set_backend(\"pytorch\")\n",
        "\n",
        "\n",
        "@aggregate_weights\n",
        "def aggregate_with_fedavg(list_of_weights: list):\n",
        "    agg_weights = []\n",
        "    for layer_index in range(len(list_of_weights[0])):\n",
        "        weights_per_layer = [weights[layer_index] for weights in list_of_weights]\n",
        "        weights_per_layer = tl.stack(weights_per_layer)\n",
        "        agg_layer = tl.mean(weights_per_layer, axis=0)\n",
        "        agg_weights.append(agg_layer)\n",
        "    return agg_weights\n",
        "\n",
        "\n",
        "# Aggregate weights\n",
        "aggregators.map(aggregate_with_fedavg)"
      ],
      "metadata": {
        "id": "YR27tyd51cfq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finalmente, agregamos los pesos al modelo de nuestro servidor/agregador. Sencillamente, para cada capa de nuestro modelo, realizamo una copia del nuevo que hemos agregado en la fase anterior."
      ],
      "metadata": {
        "id": "YQtCzF0K2i92"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from flex.pool import set_aggregated_weights\n",
        "\n",
        "\n",
        "@set_aggregated_weights\n",
        "def set_agreggated_weights_to_server(server_flex_model: FlexModel, aggregated_weights):\n",
        "    with torch.no_grad():\n",
        "        weight_dict = server_flex_model[\"model\"].state_dict()\n",
        "        for layer_key, new in zip(weight_dict, aggregated_weights):\n",
        "            weight_dict[layer_key].copy_(new)\n",
        "\n",
        "\n",
        "aggregators.map(set_agreggated_weights_to_server, servers)"
      ],
      "metadata": {
        "id": "6Fk-VxE52ZNH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos evaluar el modelo del servidor sobre el dataset de test que hemos definido anteriormente que residía en el mismo servidor. Para ello, definimos una función `evaluate_global_model` que obtenga las predicciones del modelo con el dataset de test y devuelva las metricas resultantes, que en este caso son simplemente la pérdida y la _accuracy_."
      ],
      "metadata": {
        "id": "NB5N8y2a27JU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_global_model(server_flex_model: FlexModel, test_data: Dataset):\n",
        "    model = server_flex_model[\"model\"]\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    test_acc = 0\n",
        "    total_count = 0\n",
        "    model = model.to(device)\n",
        "    criterion = server_flex_model[\"criterion\"]\n",
        "    # get test data as a torchvision object\n",
        "    test_dataset = test_data.to_torchvision_dataset(transform=mnist_transforms)\n",
        "    test_dataloader = DataLoader(\n",
        "        test_dataset, batch_size=256, shuffle=True, pin_memory=False\n",
        "    )\n",
        "    losses = []\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_dataloader:\n",
        "            total_count += target.size(0)\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            losses.append(criterion(output, target).item())\n",
        "            pred = output.data.max(1, keepdim=True)[1]\n",
        "            test_acc += pred.eq(target.data.view_as(pred)).long().cpu().sum().item()\n",
        "\n",
        "    test_loss = sum(losses) / len(losses)\n",
        "    test_acc /= total_count\n",
        "    return test_loss, test_acc\n",
        "\n",
        "\n",
        "metrics = servers.map(evaluate_global_model)\n",
        "print(\"Loss (test):\", metrics[0][0])\n",
        "print(\"Accuracy (test):\", metrics[0][1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFZA3_Sn20tn",
        "outputId": "05f7808d-8e5b-44b4-a975-70064e90715d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss (test): 1.5645130637345042\n",
            "Accuracy (test): 0.559\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para poder repetir esto en diferentes rondas, definimos la función `train_n_rounds` que aplica las funciones vistas de forma iterativa."
      ],
      "metadata": {
        "id": "4p233PYL9Lum"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_n_rounds(n_rounds, clients_per_round=20):\n",
        "    pool = FlexPool.client_server_pool(\n",
        "        fed_dataset=flex_dataset, server_id=server_id, init_func=build_server_model\n",
        "    )\n",
        "    losses = []\n",
        "    accuracies = []\n",
        "    for i in range(n_rounds):\n",
        "        print(f\"\\nRunning round: {i+1} of {n_rounds}\")\n",
        "        selected_clients_pool = pool.clients.select(clients_per_round)\n",
        "        selected_clients = selected_clients_pool.clients\n",
        "        print(f\"Selected clients for this round: {len(selected_clients)}\")\n",
        "        # Deploy the server model to the selected clients\n",
        "        pool.servers.map(copy_server_model_to_clients, selected_clients)\n",
        "        # Each selected client trains her model\n",
        "        selected_clients.map(train)\n",
        "        # The aggregador collects weights from the selected clients and aggregates them\n",
        "        pool.aggregators.map(get_clients_weights, selected_clients)\n",
        "        pool.aggregators.map(aggregate_with_fedavg)\n",
        "        # The aggregator send its aggregated weights to the server\n",
        "        pool.aggregators.map(set_agreggated_weights_to_server, pool.servers)\n",
        "        metrics = pool.servers.map(evaluate_global_model)\n",
        "        loss, acc = metrics[0]\n",
        "        losses.append(loss)\n",
        "        accuracies.append(acc)\n",
        "        print(f\"Server: Test acc: {acc:.4f}, test loss: {loss:.4f}\")\n",
        "\n",
        "    return losses, accuracies"
      ],
      "metadata": {
        "id": "OK5TLa219FLP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "losses, accuracies = train_n_rounds(15)\n",
        "plot_loss_accuracy(losses, accuracies)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AzJNwpca9rbm",
        "outputId": "768a8ae4-599e-4921-bddc-9e874e9fc4fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running round: 1 of 15\n",
            "Selected clients for this round: 20\n",
            "Server: Test acc: 0.6404, test loss: 1.5846\n",
            "\n",
            "Running round: 2 of 15\n",
            "Selected clients for this round: 20\n",
            "Server: Test acc: 0.7919, test loss: 0.9024\n",
            "\n",
            "Running round: 3 of 15\n",
            "Selected clients for this round: 20\n",
            "Server: Test acc: 0.8154, test loss: 0.6758\n",
            "\n",
            "Running round: 4 of 15\n",
            "Selected clients for this round: 20\n",
            "Server: Test acc: 0.8366, test loss: 0.5520\n",
            "\n",
            "Running round: 5 of 15\n",
            "Selected clients for this round: 20\n",
            "Server: Test acc: 0.8534, test loss: 0.4851\n",
            "\n",
            "Running round: 6 of 15\n",
            "Selected clients for this round: 20\n",
            "Server: Test acc: 0.8637, test loss: 0.4398\n",
            "\n",
            "Running round: 7 of 15\n",
            "Selected clients for this round: 20\n",
            "Server: Test acc: 0.8734, test loss: 0.4079\n",
            "\n",
            "Running round: 8 of 15\n",
            "Selected clients for this round: 20\n",
            "Server: Test acc: 0.8691, test loss: 0.4078\n",
            "\n",
            "Running round: 9 of 15\n",
            "Selected clients for this round: 20\n",
            "Server: Test acc: 0.8756, test loss: 0.3911\n",
            "\n",
            "Running round: 10 of 15\n",
            "Selected clients for this round: 20\n",
            "Server: Test acc: 0.8735, test loss: 0.4004\n",
            "\n",
            "Running round: 11 of 15\n",
            "Selected clients for this round: 20\n",
            "Server: Test acc: 0.8794, test loss: 0.3819\n",
            "\n",
            "Running round: 12 of 15\n",
            "Selected clients for this round: 20\n",
            "Server: Test acc: 0.8875, test loss: 0.3602\n",
            "\n",
            "Running round: 13 of 15\n",
            "Selected clients for this round: 20\n",
            "Server: Test acc: 0.8881, test loss: 0.3649\n",
            "\n",
            "Running round: 14 of 15\n",
            "Selected clients for this round: 20\n",
            "Server: Test acc: 0.8933, test loss: 0.3540\n",
            "\n",
            "Running round: 15 of 15\n",
            "Selected clients for this round: 20\n",
            "Server: Test acc: 0.8917, test loss: 0.3574\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Federar MNIST manualmente"
      ],
      "metadata": {
        "id": "ORA_sx5p9_cA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Federamos manualmente, usando las primitivas de FLEX, el dataset de MNIST traído desde la librería PyTorch.\n",
        "\n",
        "Dado que el algoritmo de aproximación de valores de Shapley GTG-Shapley necesita de un conjunto de validación $\\mathcal D_{\\text{val}}$, separaremos el dataset de entrenamiento en dos subconjuntos de datos: uno de entrenamieto y otro de validación, siendo el tamaño del de validación un $20\\%$ de los datos totales de entrenamiento.\n",
        "\n",
        "$$\n",
        "\\mathcal D_\\text{T} = \\mathcal D_\\text{train} \\cup \\mathcal D_\\text{val}\\\\\n",
        "\\begin{cases}\n",
        "N &= |\\mathcal D_\\text{T}|,\\\\\n",
        "N_\\text{val} &= \\lfloor 0.2 \\times N\\rfloor,\\\\\n",
        "N_\\text{train} &= N-N_\\text{val}\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "Para la distribución de los datos en un escenario de FL, establecemos un número de $K=300$ nodos sin contar el servidor central."
      ],
      "metadata": {
        "id": "O3bTDP1lYLv0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "from flex.data import Dataset, FedDatasetConfig, FedDataDistribution\n",
        "\n",
        "mnist_transforms = transforms.Compose(\n",
        "    [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]\n",
        ")\n",
        "\n",
        "train_data = datasets.MNIST(\n",
        "    root='.',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=None  # we apply them later in training process\n",
        ")\n",
        "\n",
        "test_data = datasets.MNIST(\n",
        "    root='.',\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=None  # we apply them later in training process\n",
        ")\n",
        "\n",
        "# split train data into training and validation datasets (val data ~ 20% of train data)\n",
        "val_len = math.floor(0.2 * len(train_data))\n",
        "train_len = len(train_data) - val_len\n",
        "\n",
        "train_data, val_data = random_split(train_data, [train_len, val_len])\n",
        "\n",
        "config = FedDatasetConfig(seed=33)\n",
        "config.replacement = False\n",
        "config.n_nodes = 300\n",
        "\n",
        "flex_dataset = FedDataDistribution.from_config(\n",
        "    centralized_data=Dataset.from_torchvision_dataset(train_data), config=config\n",
        ")\n",
        "\n",
        "# assign test data to server_id\n",
        "server_id = \"server\"\n",
        "flex_dataset[server_id] = Dataset.from_torchvision_dataset(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6q6w8DyUMJz",
        "outputId": "549571a9-1f14-4ca5-dc54-2edc456f0093"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:01<00:00, 6046422.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 160470.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:01<00:00, 1509301.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 3591728.65it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/flex/data/dataset.py:130: RuntimeWarning: The input dataset and arguments are not explicitly supported, therefore they might not work as expected.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inicializamos el modelo central en el servidor. El modelo de aprendizaje será un MLP (_Multi-Layer Perceptron_) de dos capas ocultas y con una función de activación ReLU para la primera capa y LogSoftmax en la capa de salida (aplicada por la función de pérdida o _criterion_ Cross-Entropy Loss)."
      ],
      "metadata": {
        "id": "DrhjfE-RdQRF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from flex.pool import init_server_model\n",
        "from flex.pool import FlexPool\n",
        "from flex.model import FlexModel\n",
        "\n",
        "# Simple Multi-Layer Perceptron\n",
        "class SimpleNet(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(28 * 28, 128)\n",
        "        self.fc2 = nn.Linear(128, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        # return logits\n",
        "        return x\n",
        "\n",
        "\n",
        "@init_server_model\n",
        "def build_server_model():\n",
        "    server_flex_model = FlexModel()\n",
        "\n",
        "    server_flex_model[\"model\"] = SimpleNet()\n",
        "    # Required to store this for later stages of the FL training process\n",
        "    server_flex_model[\"criterion\"] = torch.nn.CrossEntropyLoss()\n",
        "    server_flex_model[\"optimizer_func\"] = torch.optim.Adam\n",
        "    server_flex_model[\"optimizer_kwargs\"] = {}\n",
        "    return server_flex_model\n",
        "\n",
        "\n",
        "flex_pool = FlexPool.client_server_pool(\n",
        "    flex_dataset, server_id=server_id, init_func=build_server_model\n",
        ")\n",
        "\n",
        "clients = flex_pool.clients\n",
        "servers = flex_pool.servers\n",
        "aggregators = flex_pool.aggregators\n",
        "\n",
        "print(\n",
        "    f\"Number of nodes in the pool {len(flex_pool)}: {len(servers)} server plus {len(clients)} clients. The server is also an aggregator\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXSKTWcJb9-Q",
        "outputId": "51cd26ed-8bd4-4079-94ef-3c80018a11a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of nodes in the pool 301: 1 server plus 300 clients. The server is also an aggregator\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Asignar $\\mathcal D_\\text{val}$ a los agregadores"
      ],
      "metadata": {
        "id": "2ANAFdnMD_lp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creamos una función `save_validation_data` que guardará el conjunto de validación que hemos creado en los modelos de los agregadores."
      ],
      "metadata": {
        "id": "_rOW9A3EiPWZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from copy import deepcopy\n",
        "\n",
        "def save_validation_data(agg_flex_model: FlexModel, _test_data: Dataset, **kwargs):\n",
        "    agg_flex_model[\"val_data\"] = deepcopy(kwargs[\"val_data\"])\n",
        "\n",
        "# aggregators.map(save_validation_data, val_data=val_data)"
      ],
      "metadata": {
        "id": "whpLXVA4D9zz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agregar modelos locales usando FedAvg con pesos proporcionales a $n_k$"
      ],
      "metadata": {
        "id": "lXZDGVa3mV6W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cuando agregamos los modelos locales de los clientes existen dos opciones de agregación: agregar de forma uniforme todos los clientes $k\\in S_t$ (como se realiza en FedAvg [1]) o asignando un peso a cada cliente $k \\in S_t$ proporcional al tamaño de su conjunto de datos $n_k$.\n",
        "\n",
        "Para lograr este último redefinimos los pasos de __recolección de los pesos de los clientes__ y de __agregación__ para que:\n",
        "1. Por un lado, además de los pesos del modelo local $w_k^{(t)}$, se recupere su peso proporcional a $n_k$.\n",
        "2. Y por otro lado, agregar los modelos como una suma ponderada con los pesos proporcionales a $n_k$.\n",
        "\n",
        "> [1] https://arxiv.org/abs/1602.05629."
      ],
      "metadata": {
        "id": "2oyu8IH0lUmE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from flex.pool import collect_clients_weights\n",
        "\n",
        "@collect_clients_weights\n",
        "def get_clients_weights_with_len_weights(client_flex_model: FlexModel):\n",
        "    weight_dict = client_flex_model[\"model\"].state_dict()\n",
        "    return [weight_dict[name] for name in weight_dict], client_flex_model[\"weight\"]"
      ],
      "metadata": {
        "id": "BulGLqJ6si-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def aggregate(client_model_weights: list, client_weights: list):\n",
        "    # normalize client weights\n",
        "    total_weights = sum(client_weights)\n",
        "    norm_client_weights = torch.Tensor([w / total_weights for w in client_weights]).to(device)\n",
        "\n",
        "    agg_weights = []\n",
        "    for layer_index in range(len(client_model_weights[0])):\n",
        "        weighted_sum = torch.zeros(client_model_weights[0][layer_index].shape).to(device)\n",
        "\n",
        "        # weighted average for each client in layer\n",
        "        for client_idx in range(len(client_model_weights)):\n",
        "            weighted_sum += norm_client_weights[client_idx] * client_model_weights[client_idx][layer_index].to(device)\n",
        "\n",
        "        agg_weights.append(weighted_sum)\n",
        "\n",
        "    return agg_weights"
      ],
      "metadata": {
        "id": "QPC2uqXaR8ta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from flex.pool import aggregate_weights\n",
        "import tensorly as tl\n",
        "import numpy as np\n",
        "\n",
        "tl.set_backend(\"pytorch\")\n",
        "\n",
        "@aggregate_weights\n",
        "def model_average_aggregate(weights: list):\n",
        "    # separate client weights from model weights\n",
        "    client_model_weights = list(map(lambda w: w[0], weights))\n",
        "    client_weights = list(map(lambda w: w[1], weights))\n",
        "\n",
        "    return aggregate(client_model_weights, client_weights)"
      ],
      "metadata": {
        "id": "9XBymTrNmY-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definimos un paso inicial (no contenido en el _training loop_) en el que inicializamos los pesos de agregación de cada cliente para que sean $n_k$."
      ],
      "metadata": {
        "id": "3JLmRoOjnIG4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def init_client_weights(client_flex_model: FlexModel, client_data: Dataset):\n",
        "    \"\"\"\n",
        "    Save client weights as their dataset length.\n",
        "    \"\"\"\n",
        "    client_flex_model[\"weight\"] = float(len(client_data))"
      ],
      "metadata": {
        "id": "dKL-CMaUoVdd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Función de utilidad $\\mathcal U(w)$\n",
        "\n",
        "El algoritmo de aproximación de valores Shapley GTG-Shapley define una función $\\mathcal U(w) := -\\mathcal L(w;\\mathcal D_\\text{val})$ que estima la utilidad de un modelo $w$ sobre el conjunto de validación $\\mathcal D_\\text{val}$ negando el valor de pérdida sobre este último. De esta manera, se puede dar una función valuación a un modelo agregado que es creciente cuanto mejor predice el conjunto de validación."
      ],
      "metadata": {
        "id": "4nYtYRqRTLUX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from typing import Callable\n",
        "\n",
        "def utility(model: nn.Module, test_data: Dataset, criterion: Callable):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    test_acc = 0\n",
        "    total_count = 0\n",
        "    model = model.to(device)\n",
        "    # get test data as a torchvision object\n",
        "    test_dataset = test_data.to_torchvision_dataset(transform=mnist_transforms)\n",
        "    test_dataloader = DataLoader(\n",
        "        test_dataset, batch_size=256, shuffle=True, pin_memory=False\n",
        "    )\n",
        "    losses = []\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_dataloader:\n",
        "            total_count += target.size(0)\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            losses.append(criterion(output, target).item())\n",
        "\n",
        "    test_loss = sum(losses) / len(losses)\n",
        "    return 1 - test_loss"
      ],
      "metadata": {
        "id": "yTKpUhsOTKwX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test de convergencia\n",
        "\n",
        "En el algoritmo GTG-Shapley, se computan los valores de Shapley (contribución marginal media) para cada cliente $k \\in S_t$ sobre un número de determinado de iteraciones o hasta que los valores converjan computando el cambio medio en un número de iteraciones determinado. Definimos por tanto una función para comprobar si los valores de Shapley de un cliente han convergido en un número de mínimo $20$ iteraciones y para un umbral inferior de $1\\%$."
      ],
      "metadata": {
        "id": "FgmmVtrkmEws"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convergenceTest(values):\n",
        "    \"\"\"\n",
        "    Compute average change in last 20 iterations and if it less that 1% it has converged\n",
        "    \"\"\"\n",
        "    if len(values) < 20:\n",
        "        return False\n",
        "    else:\n",
        "        last_vals = torch.Tensor(values[-20:]).to(device)\n",
        "        last_val = torch.Tensor([values[-1]]).to(device)\n",
        "\n",
        "        # avoid division by zero\n",
        "        if last_val < 1e-6:\n",
        "            return False\n",
        "\n",
        "        return (\n",
        "            torch.mean(\n",
        "                torch.abs(last_vals - last_val)\n",
        "            )\n",
        "            / torch.abs(last_val)\n",
        "        ) < 0.01"
      ],
      "metadata": {
        "id": "EIhbuHWUFv5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GTG-SHAPLEY VALUES"
      ],
      "metadata": {
        "id": "ZSQzxhOjmK0s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementamos el algoritmo de aproximación de valores de Shapley GTG-Shapley [1]. Este algoritmo depende de la función de agregación $F$ del servidor, para lo que definimos además una función que obtenga el modelo agregado dado una lista de modelos de los clientes y sus ponderaciones.\n",
        "\n",
        "Los hiperparámetros de este algoritmo son por un lado el máximo de iteraciones $T$ para cada cliente y el umbral de error $ϵ$ para considerar la contribución al modelo agregado (si la contribución es menor que $\\epsilon$ los valores de Shapley $SV_k$ son directamente $0$). En nuestro caso, daremos $T=20 \\times M$ iteraciones ($20$ por cliente seleccionado) y un umbral $\\epsilon=10^{-4}$.\n",
        "\n",
        "> [1] https://arxiv.org/abs/2109.02053."
      ],
      "metadata": {
        "id": "MgirhEGbqWxs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from copy import deepcopy\n",
        "from typing import List\n",
        "\n",
        "def get_aggregated_model(server_model: nn.Module, client_models: List[nn.Module], client_weights: List[float]):\n",
        "    client_model_weights =  []\n",
        "    for k in client_models:\n",
        "        weight_dict = k.state_dict()\n",
        "        client_model_weights.append([weight_dict[name] for name in weight_dict])\n",
        "\n",
        "    # get aggregated weights\n",
        "    aggregated_weights = aggregate(client_model_weights, client_weights)\n",
        "\n",
        "    # copy original model\n",
        "    agg_model = deepcopy(server_model)\n",
        "\n",
        "    # set aggregated weights\n",
        "    with torch.no_grad():\n",
        "        weight_dict = agg_model.state_dict()\n",
        "        for layer_key, new in zip(weight_dict, aggregated_weights):\n",
        "            weight_dict[layer_key].copy_(new)\n",
        "\n",
        "    return agg_model"
      ],
      "metadata": {
        "id": "Z6YpgTi1WWth"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "\n",
        "MAX_ITERATIONS = 30\n",
        "EPSILON = 1e-4\n",
        "\n",
        "def shapley_values_gtg(agg_model: FlexModel, client_flex_models: List[FlexModel], **kwargs):\n",
        "    \"\"\"\n",
        "    client_states - list of client states\n",
        "    weights - weights for averaging (uniform by default)\n",
        "\n",
        "    computes shapley values for the client updates on validation dataset\n",
        "    \"\"\"\n",
        "    # get arguments\n",
        "    criterion = agg_model[\"criterion\"]\n",
        "    d_val = agg_model[\"val_data\"]\n",
        "    current_model = agg_model[\"model\"]\n",
        "    uniform_weights = kwargs[\"uniform\"] if \"uniform\" in kwargs.keys() else True\n",
        "\n",
        "    num_clients = len(client_flex_models)\n",
        "\n",
        "    # parse weights for averaging model\n",
        "    weights = [client_flex_models[k][\"weight\"] for k in client_flex_models]\n",
        "    if uniform_weights:\n",
        "        # uniform weights\n",
        "        weights = [1 / num_clients] * num_clients\n",
        "    weights = np.array(weights)\n",
        "    wtsum = np.sum(weights)\n",
        "    # normalize weights\n",
        "    weights /= wtsum\n",
        "\n",
        "    shapley_values = [[0] for i in range(num_clients)]\n",
        "    converged = False\n",
        "\n",
        "    T = MAX_ITERATIONS * num_clients\n",
        "    t = 0\n",
        "    threshold = EPSILON\n",
        "\n",
        "    # initial server model t loss\n",
        "    v_init = utility(current_model, d_val, criterion)\n",
        "\n",
        "    # final model t+1 loss\n",
        "    model_final = get_aggregated_model(\n",
        "        current_model,\n",
        "        [client_flex_models[k][\"model\"] for k in client_flex_models],\n",
        "        weights,\n",
        "    )\n",
        "    v_final = utility(model_final, d_val, criterion)\n",
        "\n",
        "    # if difference in loss on aggregated model is lower than threshold, SVs are 0 (contribution is negligible)\n",
        "    if np.abs(v_final - v_init) < threshold:\n",
        "        epsilon = 1e-9\n",
        "        return [epsilon for i in range(num_clients)]\n",
        "\n",
        "    # id-independent list of client models\n",
        "    client_models = list(client_flex_models.values())\n",
        "\n",
        "    while not converged and t < T:\n",
        "        for k in range(num_clients):\n",
        "            t += 1\n",
        "\n",
        "            # get all possible combinations of selected clients having k in idx=0\n",
        "            client_permutation = np.concatenate(\n",
        "                (\n",
        "                    np.array([k]),\n",
        "                    np.random.permutation(\n",
        "                        [i for i in range(num_clients) if i != k]\n",
        "                    )\n",
        "                )\n",
        "            ).astype(int)\n",
        "\n",
        "            v_j = v_init\n",
        "\n",
        "            for j in range(num_clients):\n",
        "                if np.abs(v_final - v_j) < threshold:\n",
        "                    v_jp1 = v_j\n",
        "                else:\n",
        "                    subset = client_permutation[: (j + 1)]\n",
        "                    client_models_subset = [client_models[i][\"model\"] for i in subset]\n",
        "                    weights_subset = [weights[i] for i in subset]\n",
        "                    # aggregate the subset-clients\n",
        "                    model_subset = get_aggregated_model(current_model, client_models_subset, weights_subset)\n",
        "                    v_jp1 = utility(model_subset, d_val, criterion)\n",
        "\n",
        "                phi_old = shapley_values[client_permutation[j]][-1]\n",
        "                phi_new = ((t - 1) * phi_old + (v_jp1 - v_j)) / t\n",
        "                shapley_values[client_permutation[j]].append(phi_new)\n",
        "                v_j = v_jp1\n",
        "\n",
        "        flag = True\n",
        "        shapley_avg = np.mean(shapley_values, axis=0)\n",
        "        if not convergenceTest(shapley_avg):\n",
        "            flag = False\n",
        "\n",
        "        if flag:\n",
        "            converged = True\n",
        "\n",
        "    if not converged:\n",
        "        print(\"not converged in SV GTG\")\n",
        "\n",
        "    final_shapley_values = [shapley_values[i][-1] for i in range(num_clients)]\n",
        "    return final_shapley_values"
      ],
      "metadata": {
        "id": "zLebmYBrJenY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import topk\n",
        "\n",
        "from flex.data import Dataset\n",
        "\n",
        "def train_n_rounds_greedy(n_rounds, clients_per_round=20):\n",
        "    pool = FlexPool.client_server_pool(\n",
        "        fed_dataset=flex_dataset, server_id=server_id, init_func=build_server_model\n",
        "    )\n",
        "\n",
        "    num_clients = len(pool.clients)\n",
        "\n",
        "    # initialize client length weights\n",
        "    pool.clients.map(init_client_weights)\n",
        "\n",
        "    # assign validation dataset to server\n",
        "    flex_val_data = Dataset.from_torchvision_dataset(val_data)\n",
        "    pool.servers.map(save_validation_data, val_data=flex_val_data)\n",
        "\n",
        "    UCB = [0 for i in range(num_clients)]\n",
        "    SV = [0 for i in range(num_clients)]\n",
        "    SV_curr = [0 for i in range(num_clients)]\n",
        "    N_t = [0 for i in range(num_clients)]\n",
        "\n",
        "    losses = []\n",
        "    accuracies = []\n",
        "    for i in range(n_rounds):\n",
        "        print(f\"\\nRunning round: {i+1} of {n_rounds}\")\n",
        "\n",
        "        # select clients to transmit weights to\n",
        "        # initially sample every client atleast once (RR)\n",
        "        selected = [False for _ in range(num_clients)]\n",
        "        if i < np.floor(num_clients / clients_per_round):\n",
        "            print(\"RR round\")\n",
        "            for idx in range(i * clients_per_round, (i + 1) * clients_per_round):\n",
        "                selected[idx] = True\n",
        "                N_t[idx] += 1\n",
        "        elif i == np.floor(num_clients / clients_per_round):\n",
        "            print(\"Last RR round\")\n",
        "            for idx in range(i * clients_per_round, num_clients):\n",
        "                selected[idx] = True\n",
        "                N_t[idx] += 1\n",
        "\n",
        "            remaining_selections = clients_per_round * (i + 1) - num_clients\n",
        "            if remaining_selections > 0:\n",
        "                unselected_indices = list(range(0, i * clients_per_round))\n",
        "                selected_indices_subset = np.random.choice(\n",
        "                    unselected_indices, size=remaining_selections, replace=False\n",
        "                )\n",
        "\n",
        "                for idx in selected_indices_subset:\n",
        "                    selected[idx] = True\n",
        "                    N_t[idx] += 1\n",
        "        else:\n",
        "            # UCB Greedy Selection (select clients with highest SV)\n",
        "            _, selected_indices = topk(torch.Tensor(UCB), clients_per_round)\n",
        "            print(\"Best selected: \", selected_indices)\n",
        "            for idx in selected_indices.tolist():\n",
        "                selected[idx] = True\n",
        "                N_t[idx] += 1\n",
        "\n",
        "        # take selected clients\n",
        "        selected_indices = [index for index, value in enumerate(selected) if value]\n",
        "        selected_clients_pool = pool.clients.select(lambda actor_id, actor_roles: actor_id in selected_indices)\n",
        "        selected_clients = selected_clients_pool.clients\n",
        "\n",
        "        print(f\"Selected clients for this round: {len(selected_clients)}\")\n",
        "\n",
        "        # Deploy the server model to the selected clients\n",
        "        pool.servers.map(copy_server_model_to_clients, selected_clients)\n",
        "\n",
        "        # Each selected client trains its model\n",
        "        selected_clients.map(train)\n",
        "\n",
        "        # The aggregador collects weights from the selected clients and aggregates them\n",
        "        pool.aggregators.map(get_clients_weights_with_len_weights, selected_clients)\n",
        "        pool.aggregators.map(model_average_aggregate)\n",
        "\n",
        "        # compute SV values for each selected client in the server\n",
        "        shapley_values = pool.aggregators.map(shapley_values_gtg, selected_clients)[0]\n",
        "\n",
        "        print(\"GTG-Shapley values: \", shapley_values)\n",
        "\n",
        "        # The aggregator send its aggregated weights to the server\n",
        "        pool.aggregators.map(set_agreggated_weights_to_server, pool.servers)\n",
        "\n",
        "        # compute the cumulative SV of each client\n",
        "        counter = 0\n",
        "        for k in range(num_clients):\n",
        "            if selected[k]:\n",
        "                SV_curr[k] = shapley_values[counter]\n",
        "\n",
        "                # previous num selections weight/penalty\n",
        "                prev_wt = (N_t[k] - 1) / N_t[k]\n",
        "                # current num selections weight/penalty\n",
        "                curr_wt = 1 - prev_wt   # 1 / N_t[k]\n",
        "\n",
        "                # previous cumulative SV\n",
        "                prev_sv = SV[k]\n",
        "\n",
        "                # t-round SV\n",
        "                curr_sv = SV_curr[k]\n",
        "\n",
        "                # compute new cumulative SV\n",
        "                SV[k] = prev_wt * prev_sv + curr_wt * curr_sv\n",
        "\n",
        "                counter += 1\n",
        "            else:\n",
        "                SV_curr[k] = 0\n",
        "\n",
        "            UCB[k] = SV[k]\n",
        "\n",
        "        metrics = pool.servers.map(evaluate_global_model)\n",
        "        loss, acc = metrics[0]\n",
        "\n",
        "        losses.append(loss)\n",
        "        accuracies.append(acc)\n",
        "        print(f\"Server: Test acc: {acc:.4f}, test loss: {loss:.4f}\")\n",
        "\n",
        "    return losses, accuracies"
      ],
      "metadata": {
        "id": "pPUTKW4d3gEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "losses, accuracies = train_n_rounds_greedy(150, clients_per_round=3)\n",
        "plot_loss_accuracy(losses, accuracies)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_wG2VpRB9Wb",
        "outputId": "3f491a64-550d-476e-cb1e-4e67f5d57885"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running round: 1 of 150\n",
            "RR round\n",
            "Selected clients for this round: 3\n",
            "GTG-Shapley values:  [0.28082140926894444, 0.4222117865943136, 0.3694769236454486]\n",
            "Server: Test acc: 0.6944, test loss: 1.2053\n",
            "\n",
            "Running round: 2 of 150\n",
            "RR round\n",
            "Selected clients for this round: 3\n",
            "GTG-Shapley values:  [0.18638246955601034, 0.20640359430931496, 0.18927515332097333]\n",
            "Server: Test acc: 0.8440, test loss: 0.6269\n",
            "\n",
            "Running round: 3 of 150\n",
            "RR round\n",
            "Selected clients for this round: 3\n",
            "GTG-Shapley values:  [0.03533198635387324, 0.04641286239194051, 0.047825965233969966]\n",
            "Server: Test acc: 0.8573, test loss: 0.4869\n",
            "\n",
            "Running round: 4 of 150\n",
            "RR round\n",
            "Selected clients for this round: 3\n",
            "GTG-Shapley values:  [0.026316463826516718, 0.014057185542378151, 0.01609528946417563]\n",
            "Server: Test acc: 0.8738, test loss: 0.4360\n",
            "\n",
            "Running round: 5 of 150\n",
            "RR round\n",
            "Selected clients for this round: 3\n",
            "GTG-Shapley values:  [0.005235784956024783, 0.018159265878111182, 0.011159723924648438]\n",
            "Server: Test acc: 0.8849, test loss: 0.3970\n",
            "\n",
            "Running round: 6 of 150\n",
            "RR round\n",
            "Selected clients for this round: 3\n",
            "GTG-Shapley values:  [0.014513243325696283, -0.010877036275351542, 0.014406934365433891]\n",
            "Server: Test acc: 0.8881, test loss: 0.3796\n",
            "\n",
            "Running round: 7 of 150\n",
            "RR round\n",
            "Selected clients for this round: 3\n",
            "GTG-Shapley values:  [0.0191411454958998, -0.008160788690427875, 0.0056747966412957025]\n",
            "Server: Test acc: 0.8900, test loss: 0.3635\n",
            "\n",
            "Running round: 8 of 150\n",
            "RR round\n",
            "Selected clients for this round: 3\n",
            "GTG-Shapley values:  [0.006736962613484554, 0.01313405303546844, -0.009784795849639719]\n",
            "Server: Test acc: 0.8946, test loss: 0.3613\n",
            "\n",
            "Running round: 9 of 150\n",
            "RR round\n",
            "Selected clients for this round: 3\n",
            "GTG-Shapley values:  [0.011352350269165918, -0.00362082810085475, -0.0034649515828342192]\n",
            "Server: Test acc: 0.8954, test loss: 0.3554\n",
            "\n",
            "Running round: 10 of 150\n",
            "RR round\n",
            "Selected clients for this round: 3\n",
            "GTG-Shapley values:  [0.01420162873306777, -0.0013815862067202316, -0.007414825071921351]\n",
            "Server: Test acc: 0.8964, test loss: 0.3457\n",
            "\n",
            "Running round: 11 of 150\n",
            "RR round\n",
            "Selected clients for this round: 3\n",
            "GTG-Shapley values:  [-0.0022392058825755827, 0.003693049223146826, -0.001075318795052716]\n",
            "Server: Test acc: 0.8970, test loss: 0.3486\n",
            "\n",
            "Running round: 12 of 150\n",
            "RR round\n",
            "Selected clients for this round: 3\n",
            "GTG-Shapley values:  [0.012858793728257389, -0.006376061637592401, 0.009773968955786907]\n",
            "Server: Test acc: 0.9041, test loss: 0.3308\n",
            "\n",
            "Running round: 13 of 150\n",
            "RR round\n",
            "Selected clients for this round: 3\n",
            "GTG-Shapley values:  [0.0020536306902026614, -0.008893440248403012, 0.007651887106492265]\n",
            "Server: Test acc: 0.9007, test loss: 0.3266\n",
            "\n",
            "Running round: 14 of 150\n",
            "RR round\n",
            "Selected clients for this round: 3\n",
            "GTG-Shapley values:  [0.0010185992796249406, 0.005458976933779798, 0.002152331920742606]\n",
            "Server: Test acc: 0.9040, test loss: 0.3225\n",
            "\n",
            "Running round: 15 of 150\n",
            "RR round\n",
            "Selected clients for this round: 3\n",
            "GTG-Shapley values:  [-0.013238477247947387, 0.02215478598709165, 0.001644422776672496]\n",
            "Server: Test acc: 0.9069, test loss: 0.3205\n",
            "\n",
            "Running round: 16 of 150\n",
            "RR round\n",
            "Selected clients for this round: 3\n",
            "not converged in SV GTG\n",
            "GTG-Shapley values:  [0.0031653718076135482, -0.020020573151167977, 0.006322079527039895]\n",
            "Server: Test acc: 0.9029, test loss: 0.3337\n",
            "\n",
            "Running round: 17 of 150\n",
            "RR round\n",
            "Selected clients for this round: 3\n",
            "GTG-Shapley values:  [0.01913288718782055, -0.012393580487313136, 0.00919166396031387]\n",
            "Server: Test acc: 0.9042, test loss: 0.3097\n",
            "\n",
            "Running round: 18 of 150\n",
            "RR round\n",
            "Selected clients for this round: 3\n",
            "GTG-Shapley values:  [-0.00030738636171923604, -0.007936001518456262, 0.015007141332133586]\n",
            "Server: Test acc: 0.9081, test loss: 0.3044\n",
            "\n",
            "Running round: 19 of 150\n",
            "RR round\n",
            "Selected clients for this round: 3\n",
            "not converged in SV GTG\n",
            "GTG-Shapley values:  [0.0024396381127355354, -0.01188743250448933, -0.0010762917481133621]\n",
            "Server: Test acc: 0.9073, test loss: 0.3248\n",
            "\n",
            "Running round: 20 of 150\n",
            "RR round\n",
            "Selected clients for this round: 3\n",
            "GTG-Shapley values:  [0.0069720915687603935, -0.013212397362444284, 0.014338795250430802]\n",
            "Server: Test acc: 0.9099, test loss: 0.3142\n",
            "\n",
            "Running round: 21 of 150\n",
            "RR round\n",
            "Selected clients for this round: 3\n",
            "GTG-Shapley values:  [0.015489116535647501, -0.015440003556721198, 0.007879499445094687]\n",
            "Server: Test acc: 0.9151, test loss: 0.2882\n",
            "\n",
            "Running round: 22 of 150\n",
            "RR round\n",
            "Selected clients for this round: 3\n",
            "GTG-Shapley values:  [-0.0047517769989815035, -0.010037883389609087, 0.017171260801718626]\n",
            "Server: Test acc: 0.9150, test loss: 0.3256\n",
            "\n",
            "Running round: 23 of 150\n",
            "RR round\n",
            "Selected clients for this round: 3\n",
            "not converged in SV GTG\n",
            "GTG-Shapley values:  [-0.010599707008887686, -0.0163538649907208, 0.014319787347077183]\n",
            "Server: Test acc: 0.9112, test loss: 0.3014\n",
            "\n",
            "Running round: 24 of 150\n",
            "RR round\n",
            "Selected clients for this round: 3\n",
            "not converged in SV GTG\n",
            "GTG-Shapley values:  [0.014383536165064924, -0.024477951232141373, -0.0004879316645311444]\n",
            "Server: Test acc: 0.9121, test loss: 0.3172\n",
            "\n",
            "Running round: 25 of 150\n",
            "RR round\n",
            "Selected clients for this round: 3\n",
            "GTG-Shapley values:  [-0.004168303874005156, -0.00733220998458222, 0.030680150654178274]\n",
            "Server: Test acc: 0.9114, test loss: 0.2945\n",
            "\n",
            "Running round: 26 of 150\n",
            "RR round\n",
            "Selected clients for this round: 3\n",
            "GTG-Shapley values:  [0.009046437590559437, 0.009285881330297825, -0.005059612180807442]\n",
            "Server: Test acc: 0.9162, test loss: 0.2928\n",
            "\n",
            "Running round: 27 of 150\n",
            "RR round\n",
            "Selected clients for this round: 3\n",
            "GTG-Shapley values:  [0.00565684483346001, 0.00536185884970902, 0.0057312811610667185]\n",
            "Server: Test acc: 0.9192, test loss: 0.2772\n",
            "\n",
            "Running round: 28 of 150\n",
            "RR round\n",
            "Selected clients for this round: 3\n",
            "not converged in SV GTG\n",
            "GTG-Shapley values:  [-0.017442347010681234, -0.0009480315496171698, -0.0005409139162259701]\n",
            "Server: Test acc: 0.9156, test loss: 0.2925\n",
            "\n",
            "Running round: 29 of 150\n",
            "RR round\n",
            "Selected clients for this round: 3\n",
            "GTG-Shapley values:  [0.027385149939927394, -0.013392862932720705, -0.007018539718641954]\n",
            "Server: Test acc: 0.9201, test loss: 0.2918\n",
            "\n",
            "Running round: 30 of 150\n",
            "RR round\n",
            "Selected clients for this round: 3\n",
            "GTG-Shapley values:  [-0.00015962733806932202, 0.0005603062013483083, 0.013501504770165842]\n",
            "Server: Test acc: 0.9240, test loss: 0.2696\n",
            "\n",
            "Running round: 31 of 150\n",
            "RR round\n",
            "Selected clients for this round: 3\n",
            "GTG-Shapley values:  [-0.0001387407638985479, 0.001867500912273538, 0.001998279806086853]\n",
            "Server: Test acc: 0.9228, test loss: 0.2715\n",
            "\n",
            "Running round: 32 of 150\n",
            "RR round\n",
            "Selected clients for this round: 3\n",
            "not converged in SV GTG\n",
            "GTG-Shapley values:  [0.0016479743094168183, -0.010276822832106982, 0.0036946414826750464]\n",
            "Server: Test acc: 0.9193, test loss: 0.2853\n",
            "\n",
            "Running round: 33 of 150\n",
            "RR round\n",
            "Selected clients for this round: 3\n",
            "GTG-Shapley values:  [-0.008067762779247452, 0.006994833239366474, 0.007301719989457775]\n",
            "Server: Test acc: 0.9217, test loss: 0.2776\n",
            "\n",
            "Running round: 34 of 150\n",
            "RR round\n",
            "Selected clients for this round: 3\n",
            "GTG-Shapley values:  [0.0019240672902978574, 0.0068919612915682585, 0.005837994287018843]\n",
            "Server: Test acc: 0.9249, test loss: 0.2613\n",
            "\n",
            "Running round: 35 of 150\n",
            "RR round\n",
            "Selected clients for this round: 3\n",
            "not converged in SV GTG\n",
            "GTG-Shapley values:  [-0.0005370018752753891, 0.01847913659422113, -0.02647719972416861]\n",
            "Server: Test acc: 0.9219, test loss: 0.2748\n",
            "\n",
            "Running round: 36 of 150\n",
            "RR round\n",
            "Selected clients for this round: 3\n",
            "GTG-Shapley values:  [0.028858294579615373, -0.019689479868001587, -0.007991208574181596]\n",
            "Server: Test acc: 0.9235, test loss: 0.2722\n",
            "\n",
            "Running round: 37 of 150\n",
            "RR round\n",
            "Selected clients for this round: 3\n",
            "GTG-Shapley values:  [0.0016754276695705437, 0.009763513171805656, -0.0029894299314497837]\n",
            "Server: Test acc: 0.9262, test loss: 0.2585\n",
            "\n",
            "Running round: 38 of 150\n",
            "RR round\n",
            "Selected clients for this round: 3\n",
            "not converged in SV GTG\n",
            "GTG-Shapley values:  [0.015367701802904721, -0.02220784406536578, -0.0067344265820427724]\n",
            "Server: Test acc: 0.9238, test loss: 0.2584\n",
            "\n",
            "Running round: 39 of 150\n",
            "RR round\n",
            "Selected clients for this round: 3\n",
            "GTG-Shapley values:  [-0.005491964828521169, 0.021399365551203565, 0.003348812000427787]\n",
            "Server: Test acc: 0.9286, test loss: 0.2461\n",
            "\n",
            "Running round: 40 of 150\n",
            "RR round\n",
            "Selected clients for this round: 3\n",
            "not converged in SV GTG\n",
            "GTG-Shapley values:  [0.025865314666613345, -0.015144062227179783, -0.03136049068530679]\n",
            "Server: Test acc: 0.9300, test loss: 0.2527\n",
            "\n",
            "Running round: 41 of 150\n",
            "RR round\n",
            "Selected clients for this round: 3\n",
            "GTG-Shapley values:  [0.01170905372231686, 0.003057231543455428, -0.0071723328293758675]\n",
            "Server: Test acc: 0.9309, test loss: 0.2730\n",
            "\n",
            "Running round: 42 of 150\n",
            "RR round\n",
            "Selected clients for this round: 3\n",
            "GTG-Shapley values:  [0.029848327714923448, 0.014659078823819607, -0.021038585483061617]\n",
            "Server: Test acc: 0.9338, test loss: 0.2544\n",
            "\n",
            "Running round: 43 of 150\n",
            "RR round\n",
            "Selected clients for this round: 3\n",
            "not converged in SV GTG\n",
            "GTG-Shapley values:  [-0.010608992810156329, -0.0034179024468781443, -0.00010347031497222911]\n",
            "Server: Test acc: 0.9314, test loss: 0.2473\n",
            "\n",
            "Running round: 44 of 150\n",
            "RR round\n",
            "Selected clients for this round: 3\n",
            "GTG-Shapley values:  [0.0022379103085552678, -0.0021070012673660076, 0.003076527898012086]\n",
            "Server: Test acc: 0.9305, test loss: 0.2399\n",
            "\n",
            "Running round: 45 of 150\n",
            "RR round\n",
            "Selected clients for this round: 3\n",
            "GTG-Shapley values:  [0.009152541474911978, -0.0020286773219175824, 0.003080060069563443]\n",
            "Server: Test acc: 0.9336, test loss: 0.2384\n",
            "\n",
            "Running round: 46 of 150\n",
            "RR round\n",
            "Selected clients for this round: 3\n",
            "not converged in SV GTG\n",
            "GTG-Shapley values:  [0.009877095986201713, -0.0018170667543619709, -0.009760308535175097]\n",
            "Server: Test acc: 0.9331, test loss: 0.2376\n",
            "\n",
            "Running round: 47 of 150\n",
            "RR round\n",
            "Selected clients for this round: 3\n",
            "GTG-Shapley values:  [0.009308213279360832, 0.032869482980975015, -0.0291699896573175]\n",
            "Server: Test acc: 0.9345, test loss: 0.2244\n",
            "\n",
            "Running round: 48 of 150\n",
            "RR round\n",
            "Selected clients for this round: 3\n",
            "not converged in SV GTG\n",
            "GTG-Shapley values:  [0.012826384591647646, -0.012662691128028473, -0.015841609100430296]\n",
            "Server: Test acc: 0.9300, test loss: 0.2484\n",
            "\n",
            "Running round: 49 of 150\n",
            "RR round\n",
            "Selected clients for this round: 3\n",
            "not converged in SV GTG\n",
            "GTG-Shapley values:  [0.013254527663085472, -0.0059887723490842345, -0.007763705828863388]\n",
            "Server: Test acc: 0.9289, test loss: 0.2513\n",
            "\n",
            "Running round: 50 of 150\n",
            "RR round\n",
            "Selected clients for this round: 3\n",
            "GTG-Shapley values:  [-0.0012098159773129822, 0.022966947281976624, -0.011973853335312909]\n",
            "Server: Test acc: 0.9337, test loss: 0.2433\n",
            "\n",
            "Running round: 51 of 150\n",
            "RR round\n",
            "Selected clients for this round: 3\n",
            "GTG-Shapley values:  [0.009582772775503182, 0.00033623556084668875, 0.003802264677294609]\n",
            "Server: Test acc: 0.9377, test loss: 0.2231\n",
            "\n",
            "Running round: 52 of 150\n",
            "RR round\n",
            "Selected clients for this round: 3\n",
            "not converged in SV GTG\n",
            "GTG-Shapley values:  [-0.006596982900062085, -0.0026548552192553945, -0.005953810853667872]\n",
            "Server: Test acc: 0.9359, test loss: 0.2257\n",
            "\n",
            "Running round: 53 of 150\n",
            "RR round\n",
            "Selected clients for this round: 3\n",
            "GTG-Shapley values:  [0.0018721937212296562, 0.008132432875239506, -0.0025652869554517784]\n",
            "Server: Test acc: 0.9365, test loss: 0.2202\n",
            "\n",
            "Running round: 54 of 150\n",
            "RR round\n",
            "Selected clients for this round: 3\n",
            "not converged in SV GTG\n",
            "GTG-Shapley values:  [0.0016308494105970572, -0.009232477678192965, 0.007196817909924436]\n",
            "Server: Test acc: 0.9388, test loss: 0.2272\n",
            "\n",
            "Running round: 55 of 150\n",
            "RR round\n",
            "Selected clients for this round: 3\n",
            "not converged in SV GTG\n",
            "GTG-Shapley values:  [-0.006123487720041408, -0.007288834362799392, 0.011700656777578035]\n",
            "Server: Test acc: 0.9341, test loss: 0.2282\n",
            "\n",
            "Running round: 56 of 150\n",
            "RR round\n",
            "Selected clients for this round: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "losses, accuracies = train_n_rounds(15, 200)\n",
        "plot_loss_accuracy(losses, accuracies)"
      ],
      "metadata": {
        "id": "8NO0jhXgf-gw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "losses, accuracies = train_n_rounds_afl(15, 200)\n",
        "plot_loss_accuracy(losses, accuracies)"
      ],
      "metadata": {
        "id": "fNHZXcLripPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ALPHA3 = 0.4\n",
        "losses, accuracies = train_n_rounds_afl(15, 200)\n",
        "plot_loss_accuracy(losses, accuracies)"
      ],
      "metadata": {
        "id": "l3r0nbCmpF4w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ga_F2xKqpMY7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}